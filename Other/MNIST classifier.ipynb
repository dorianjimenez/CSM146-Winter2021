{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "# Imports\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "import torchvision.datasets as datasets\r\n",
    "import torchvision.transforms as transforms\r\n",
    "\r\n",
    "import wandb\r\n",
    "\r\n",
    "wandb.login()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "# Device\r\n",
    "\r\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n",
    "print(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "# Define Hyperparameters\r\n",
    "\r\n",
    "config = dict (\r\n",
    "    input_size=784,\r\n",
    "    epochs=1, \r\n",
    "    classes=10,\r\n",
    "    kernels=[50,50],\r\n",
    "    batch_size=64,\r\n",
    "    learning_rate=0.005,\r\n",
    "    dataset=\"MNIST\",\r\n",
    "    architecture=\"ANN\"\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "# Model Pipeline\r\n",
    "\r\n",
    "def model_pipeline(hyperparameters):\r\n",
    "\r\n",
    "    with wandb.init(project=\"wandb_test\", config=hyperparameters):\r\n",
    "        \r\n",
    "        config = wandb.config\r\n",
    "\r\n",
    "        train_loader, test_loader = make_data(config)\r\n",
    "        \r\n",
    "        model, criterion, optimizer = make_model(config)\r\n",
    "        print(model)\r\n",
    "\r\n",
    "        train(model, train_loader, criterion, optimizer, config)\r\n",
    "\r\n",
    "        test(model, test_loader)\r\n",
    "\r\n",
    "    return model\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# Make Data\r\n",
    "\r\n",
    "def make_data(config):\r\n",
    "\r\n",
    "    train_dataset = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)\r\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=config.batch_size, shuffle=True)\r\n",
    "\r\n",
    "    test_dataset = datasets.MNIST(root='dataset/', train=False, transform=transforms.ToTensor(), download=True)\r\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=config.batch_size, shuffle=True)\r\n",
    " \r\n",
    "    return train_loader, test_loader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "# Make Model\r\n",
    "\r\n",
    "class NeuralNetwork(nn.Module):\r\n",
    "\r\n",
    "    def __init__(self, input_size, kernels, classes):\r\n",
    "        super(NeuralNetwork, self).__init__()\r\n",
    "        self.layer1 = nn.Linear(input_size, kernels[0])\r\n",
    "        self.layer2 = nn.Linear(kernels[0], kernels[1])\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        output = F.relu(self.layer1(x))\r\n",
    "        output = self.layer2(output)\r\n",
    "        return output\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "def make_model(config):\r\n",
    "    \r\n",
    "    model = NeuralNetwork(input_size=config.input_size, kernels=config.kernels, classes=config.classes).to(device)\r\n",
    "\r\n",
    "    criterion = nn.CrossEntropyLoss()\r\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\r\n",
    "\r\n",
    "    return model, criterion, optimizer\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "# Train Model\r\n",
    "\r\n",
    "def train(model, train_loader, criterion, optimizer, config):\r\n",
    "\r\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=5)\r\n",
    "\r\n",
    "    for epoch in range(config.epochs):\r\n",
    "        for batch_index, (data, targets) in enumerate(train_loader):\r\n",
    "\r\n",
    "            loss = train_batch(data, targets, model, optimizer, criterion)\r\n",
    "\r\n",
    "            if((batch_index + 1) % 10) == 0:\r\n",
    "                train_log(loss, epoch, batch_index)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "def train_batch(data, targets, model, optimizer, criterion):\r\n",
    "\r\n",
    "    data = data.to(device=device)\r\n",
    "    targets = targets.to(device=device)\r\n",
    "\r\n",
    "    data = data.reshape(data.shape[0], -1)\r\n",
    "\r\n",
    "    scores = model(data)\r\n",
    "    loss = criterion(scores, targets)\r\n",
    "\r\n",
    "    optimizer.zero_grad()\r\n",
    "    loss.backward()\r\n",
    "\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    return loss\r\n",
    "\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "def train_log(loss, epoch, batch_index):\r\n",
    "    loss = float(loss)\r\n",
    "\r\n",
    "    wandb.log({\"epoch:\": epoch, \"loss\": loss}, step=batch_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "def test(model, test_loader):\r\n",
    "    model.eval()\r\n",
    "\r\n",
    "    with torch.no_grad():\r\n",
    "        correct, total = 0, 0\r\n",
    "        for data, target in test_loader:\r\n",
    "            data = data.to(device=device)\r\n",
    "            target = target.to(device=device)\r\n",
    "\r\n",
    "            data = data.reshape(data.shape[0], -1)\r\n",
    "\r\n",
    "            score = model(data)\r\n",
    "            _, predicted = torch.max(score.data, 1)\r\n",
    "            total += target.size(0)\r\n",
    "            correct += (predicted == target).sum().item()\r\n",
    "\r\n",
    "        wandb.log({\"test_accuracy\": correct / total})\r\n",
    "\r\n",
    "  \r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "model_pipeline(config)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">eternal-snow-13</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/dxinhua/wandb_test\" target=\"_blank\">https://wandb.ai/dxinhua/wandb_test</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/dxinhua/wandb_test/runs/1a705inq\" target=\"_blank\">https://wandb.ai/dxinhua/wandb_test/runs/1a705inq</a><br/>\n",
       "                Run data is saved locally in <code>c:\\Users\\dxinh\\Documents\\AA_PYTHON_SCRIPTS\\Tests\\wandb\\run-20210912_043640-1a705inq</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NeuralNetwork(\n",
      "  (layer1): Linear(in_features=784, out_features=50, bias=True)\n",
      "  (layer2): Linear(in_features=50, out_features=50, bias=True)\n",
      ")\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 12924<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc7962dff8c048ecb9fa151e02698658"
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.0, max=1.0)…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>c:\\Users\\dxinh\\Documents\\AA_PYTHON_SCRIPTS\\Tests\\wandb\\run-20210912_043640-1a705inq\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>c:\\Users\\dxinh\\Documents\\AA_PYTHON_SCRIPTS\\Tests\\wandb\\run-20210912_043640-1a705inq\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>26</td></tr><tr><td>_timestamp</td><td>1631446626</td></tr><tr><td>_step</td><td>929</td></tr><tr><td>epoch:</td><td>0</td></tr><tr><td>loss</td><td>0.05207</td></tr><tr><td>test_accuracy</td><td>0.9516</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇█</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇█</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch:</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▄▃▂▂▃▃▂▃▂▂▃▂▁▂▂▂▁▁▁▂▂▁▂▁▂▁▂▂▃▂▂▂▁▂▁▂▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">eternal-snow-13</strong>: <a href=\"https://wandb.ai/dxinhua/wandb_test/runs/1a705inq\" target=\"_blank\">https://wandb.ai/dxinhua/wandb_test/runs/1a705inq</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (layer1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer2): Linear(in_features=50, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "f016af825e4955bae841aa079394af2f912bbcdc4bad84c2dca855cba020ba0f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}